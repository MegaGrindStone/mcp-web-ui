port: 8080
# Choose one of the following LLM providers: ollama, anthropic
llm:
  provider: ollama
  model: claude-3-5-sonnet-20241022
  # ollama
  host: http://localhost:11434 # Default to environment variable OLLAMA_HOST
  # anthropic
  apiKey: YOUR_API_KEY # Default to environment variable ANTHROPIC_API_KEY
  maxTokens: 1000
mcpStdIOServers:
  filesystem:
    command: npx
    args:
      - -y
      - "@modelcontextprotocol/server-filesystem"
      - "/home/gs/repository/go-mcp"
